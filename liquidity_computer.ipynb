{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83760675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import csv\n",
    "from helpers import config\n",
    "from helpers.loading import *\n",
    "from helpers.algorithm import find_best_delay \n",
    "from helpers.preprocessing import *\n",
    "from helpers.dask import *\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import time\n",
    "import dask \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6284fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dates = get_all_dates()\n",
    "print(f\"{len(all_dates)} dates to process\")\n",
    "signal = config['signal']\n",
    "print(f\"working on signal : {signal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df79dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldnames = ['date','market',\"period\"]\n",
    "\n",
    "@dask.delayed\n",
    "def compute_liquidity(start_date_idx,end_date_idx,verbose=0):\n",
    "    # file where to write the computed prediods\n",
    "    results_path = config[\"files\"][\"results\"][signal][\"dask_calculation\"][\"liquidity\"].format(f\"{start_date_idx}_{end_date_idx}\")\n",
    "\n",
    "    result_file_exists = file_exist(results_path) \n",
    "    csvfile = open(results_path, 'a', newline='') \n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    if result_file_exists:\n",
    "        processed_dates = set(pd.read_csv(results_path).date.unique())\n",
    "    else: \n",
    "        # if the file is new, we need to write headers\n",
    "        writer.writeheader()\n",
    "        processed_dates = set()\n",
    "\n",
    "\n",
    "    max_iterations = 5000\n",
    "    start_time = time.time()\n",
    "    date_count = 0 # number of dates processed\n",
    "    dates_to_process = all_dates[start_date_idx:end_date_idx]\n",
    "    for date_id,date in enumerate(dates_to_process):\n",
    "        if verbose >0:\n",
    "            print(f\"date:{date}, {date_id}:{len(dates_to_process)}, {100*date_id/len(dates_to_process):0.3f}%\", end=\"\\r\")\n",
    "\n",
    "        daily_data = load_daily_data(date,preprocessing_steps=[\"numeric\"])\n",
    "        if not daily_data:\n",
    "            # in case all markets do not provide data for the given date, we skip the date\n",
    "            continue\n",
    "\n",
    "        # we skip the current date if it has already been processed\n",
    "        if date in processed_dates:\n",
    "            continue\n",
    "\n",
    "        for market in daily_data:\n",
    "            period = daily_data[market].reset_index().date.diff(1).median().total_seconds()\n",
    "            writer.writerow({'date': date, 'market': market,\"period\" : period})\n",
    "\n",
    "        csvfile.flush() # flush every time we processed a date\n",
    "        date_count+=1\n",
    "        if date_count>=max_iterations:\n",
    "            break\n",
    "    print()\n",
    "    print(f\"{date_count} dates processed in {time.time()-start_time:0.2f}s\")\n",
    "    csvfile.close()\n",
    "    return results_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e886fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(all_dates)\n",
    "k = 5 # number of partitions\n",
    "t = N//k # number of dates to process per worker\n",
    "dask.config.set(scheduler=\"processes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1341bffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_liquidity_dask():\n",
    "    promises = []\n",
    "    for start_date_idx in range(0,N,t):\n",
    "        end_date_idx = start_date_idx+t\n",
    "        promise = compute_liquidity(start_date_idx,end_date_idx)\n",
    "        promises.append(promise)\n",
    "        \n",
    "    dask_compututation(promises,config[\"files\"][\"results\"][signal][\"liquidity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05f657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_liquidity_dask()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
